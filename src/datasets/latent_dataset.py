"""
Dataset for MeanFlow training using pre-processed .pt files.

This dataset loads Latent and Edge pairs directly from .pt files generated by
preprocess_all.py. It is the most efficient method as it avoids:
1. Reading separate PNG files.
2. Runtime resizing/interpolation.
3. Runtime normalization.

Expected .pt content:
    - "latent": [4, 32, 32] tensor in range approx [-2, 2] (VAE scaled)
    - "edge":   [1, 256, 256] tensor in range [-1, 1]
"""

from __future__ import annotations

import random
from pathlib import Path

import torch
from torch.utils.data import Dataset


def _default_categories(categories: list[str] | None) -> list[str]:
    if categories is None or categories == ["all"]:
        return ["cat", "dog", "wild"]
    return categories


class LatentEdgeDataset(Dataset):
    """Fast dataset loading pre-processed latents and edges from .pt files.

    Args:
        root_dir: Directory containing the split folders (train/val).
        split: Dataset split ("train" or "val").
        categories: List of categories to include (e.g., ["cat", "dog"]).
        augment: Whether to apply horizontal flip augmentation.
    """

    def __init__(
        self,
        root_dir: str,
        split: str = "train",
        categories: list | None = None,
        augment: bool = True,
    ):
        self.root_dir = Path(root_dir)
        self.split = split
        self.augment = bool(augment) and (split == "train")

        self.categories = _default_categories(categories)

        split_dir = self.root_dir / split
        if not split_dir.exists():
            raise ValueError(f"Split directory not found: {split_dir}")

        self.samples: list[Path] = []
        for category in self.categories:
            cat_dir = split_dir / category
            if not cat_dir.exists():
                print(f"Warning: Category directory not found: {cat_dir}")
                continue
            # Find all .pt files
            self.samples.extend(sorted(cat_dir.glob("*_latent.pt")))

        if not self.samples:
            raise ValueError(f"No .pt samples found in {split_dir}")

        print(f"[{split.upper()}] Loaded {len(self.samples)} samples")

    def __len__(self) -> int:
        return len(self.samples)

    def __getitem__(self, idx: int):
        latent_path = self.samples[idx]
        # Load data (contains both 'latent' and 'edge')
        data = torch.load(latent_path, map_location="cpu", weights_only=True)

        latent = data["latent"]  # [4, 32, 32]
        edge = data["edge"]  # [1, 256, 256]

        # Sanity check: Ensure edge has single channel
        if edge.dim() == 4 and edge.shape[-1] == 3:
            edge = edge[..., 0]
        elif edge.dim() == 3 and edge.shape[-1] == 3:
            edge = edge[..., 0]

        # Sanity check: Ensure edge is float [-1, 1]
        # (preprocess_all.py should have saved it as float, but just in case)
        if edge.dtype == torch.uint8:
            edge = edge.float() / 255.0 * 2.0 - 1.0

        # Ensure channel dimension exists [1, H, W]
        if edge.dim() == 2:
            edge = edge.unsqueeze(0)

        # Augmentation: Random Horizontal Flip
        # Flipping both latent and edge synchronously
        if self.augment and (random.random() < 0.5):
            latent = torch.flip(latent, dims=[-1])
            edge = torch.flip(edge, dims=[-1])

        return latent, edge
